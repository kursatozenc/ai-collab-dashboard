{
  "clusters": [
    { "id": "trust", "label": "Trust & Reliability" },
    { "id": "delegation", "label": "Task Delegation & Autonomy" },
    { "id": "communication", "label": "Human-AI Communication" },
    { "id": "teamwork", "label": "Team Dynamics & Coordination" },
    { "id": "learning", "label": "Learning & Adaptation" },
    { "id": "ethics", "label": "Ethics & Responsible AI" },
    { "id": "creativity", "label": "Co-Creativity & Innovation" }
  ],
  "nodes": [
    {
      "id": "trust-digital-teams",
      "title": "Trust in Digital Human-AI Team Collaboration: A Systematic Review",
      "authors": "Various",
      "year": 2024,
      "cluster": "trust",
      "summary": "Systematic review synthesizing trust dynamics in digital human-AI teams, identifying key factors like transparency, predictability, and shared mental models that influence trust calibration.",
      "url": "",
      "source": "research",
      "designLevers": ["interface", "governance"],
      "designerIntents": ["team_structure", "governance_policy"],
      "designQuestion": "How might we design transparency mechanisms that help teams calibrate trust appropriately rather than defaulting to over- or under-trust?",
      "tags": ["trust", "systematic-review", "transparency"],
      "embedding": [185, 130]
    },
    {
      "id": "shaping-trust",
      "title": "Shaping a Multidisciplinary Understanding of Team Trust in Human-AI Teams",
      "authors": "Various",
      "year": 2024,
      "cluster": "trust",
      "summary": "Proposes a theoretical framework bridging organizational psychology and AI research to understand how trust develops, erodes, and is repaired in human-AI team contexts.",
      "url": "",
      "source": "research",
      "designLevers": ["ritual", "role"],
      "designerIntents": ["team_structure", "ritual_design"],
      "designQuestion": "What rituals could help teams repair trust after an AI teammate makes a significant error?",
      "tags": ["trust", "framework", "emerging"],
      "embedding": [220, 170]
    },
    {
      "id": "impacts-trust-model",
      "title": "IMPACTS: A Trust Model for Human-Autonomy Teaming",
      "authors": "Hou et al.",
      "year": 2021,
      "cluster": "trust",
      "summary": "Introduces the IMPACTS trust model for human-autonomy teaming, decomposing trust into measurable factors including intent, measurability, performance, adaptability, communication, transparency, and security.",
      "url": "",
      "source": "research",
      "designLevers": ["interface", "governance"],
      "designerIntents": ["governance_policy", "tooling_selection"],
      "designQuestion": "Which of the seven IMPACTS trust factors is most critical for your team's context, and how would you measure it?",
      "tags": ["trust", "model", "measurement"],
      "embedding": [170, 185]
    },
    {
      "id": "trust-ai-team-member",
      "title": "Would You Trust an AI Team Member? Team Trust in Human-AI Teams",
      "authors": "Georganta et al.",
      "year": 2024,
      "cluster": "trust",
      "summary": "Empirical study on trust formation with AI team members, finding that trust in AI teammates follows different trajectories than interpersonal trust and requires distinct calibration.",
      "url": "",
      "source": "research",
      "designLevers": ["ritual", "interface"],
      "designerIntents": ["team_structure", "ritual_design"],
      "designQuestion": "How should onboarding rituals differ when a new AI teammate joins versus a new human teammate?",
      "tags": ["trust", "empirical", "calibration", "emerging"],
      "embedding": [230, 140]
    },
    {
      "id": "ideal-human",
      "title": "An Ideal Human: Expectations of AI Teammates in Human-AI Teaming",
      "authors": "Various",
      "year": 2024,
      "cluster": "teamwork",
      "summary": "Investigates what humans expect from AI teammates, finding that people project human-like qualities onto AI partners and that unmet expectations significantly impact team performance.",
      "url": "",
      "source": "research",
      "designLevers": ["role", "interface"],
      "designerIntents": ["role_definition", "team_structure"],
      "designQuestion": "How might we set realistic expectations for AI teammates to avoid the disappointment cycle of anthropomorphic projection?",
      "tags": ["expectations", "anthropomorphism", "performance"],
      "embedding": [480, 280]
    },
    {
      "id": "tools-to-teammates",
      "title": "From Tools to Teammates: Reconceptualizing AI in Organizations",
      "authors": "Various",
      "year": 2024,
      "cluster": "teamwork",
      "summary": "Explores the paradigm shift from viewing AI as a tool to treating it as a teammate, examining implications for organizational design, team composition, and management practices.",
      "url": "",
      "source": "research",
      "designLevers": ["role", "governance"],
      "designerIntents": ["team_structure", "role_definition"],
      "designQuestion": "Where on the tool-to-teammate spectrum should AI sit in your organization, and what changes as you move along that spectrum?",
      "tags": ["paradigm-shift", "organizational-design", "emerging"],
      "embedding": [520, 320]
    },
    {
      "id": "beyond-tool-teammate",
      "title": "Beyond the Tool vs. Teammate Debate: Exploring the Spectrum",
      "authors": "Various",
      "year": 2024,
      "cluster": "teamwork",
      "summary": "Argues against the binary tool/teammate framing, proposing a spectrum of AI integration levels in teams with distinct interaction patterns and design requirements at each level.",
      "url": "",
      "source": "research",
      "designLevers": ["role", "workflow"],
      "designerIntents": ["role_definition", "workflow_redesign"],
      "designQuestion": "What does each level of the AI integration spectrum look like in practice for your team's daily workflows?",
      "tags": ["spectrum", "integration-levels", "framework"],
      "embedding": [540, 285]
    },
    {
      "id": "who-what-teammate",
      "title": "Who/What Is My Teammate? Team Composition Considerations in Human-AI Teaming",
      "authors": "Various",
      "year": 2023,
      "cluster": "teamwork",
      "summary": "Examines how introducing AI agents changes team composition dynamics, including role allocation, expertise distribution, and the emergence of new coordination challenges.",
      "url": "",
      "source": "research",
      "designLevers": ["role", "workflow"],
      "designerIntents": ["team_structure", "role_definition"],
      "designQuestion": "How does adding an AI agent change the optimal size and composition of your team?",
      "tags": ["composition", "coordination", "role-allocation"],
      "embedding": [465, 330]
    },
    {
      "id": "when-ai-joins",
      "title": "When AI Joins the Team: A Literature Review on Intragroup Processes",
      "authors": "Various",
      "year": 2024,
      "cluster": "teamwork",
      "summary": "Reviews literature on how AI integration affects intragroup processes including communication patterns, conflict resolution, decision-making, and group identity formation.",
      "url": "",
      "source": "research",
      "designLevers": ["ritual", "workflow"],
      "designerIntents": ["team_structure", "workflow_redesign"],
      "designQuestion": "Which intragroup processes need to be redesigned when AI becomes a permanent team member?",
      "tags": ["intragroup", "processes", "literature-review"],
      "embedding": [510, 345]
    },
    {
      "id": "defining-hat",
      "title": "Defining Human-AI Teaming",
      "authors": "Berretta et al.",
      "year": 2023,
      "cluster": "teamwork",
      "summary": "Provides a comprehensive definition of human-AI teaming that distinguishes it from human-AI interaction, emphasizing interdependence, shared goals, and adaptive coordination.",
      "url": "",
      "source": "research",
      "designLevers": ["role", "governance"],
      "designerIntents": ["team_structure", "governance_policy"],
      "designQuestion": "Does your team's AI use qualify as 'teaming' or just 'interaction'? What would need to change to reach true interdependence?",
      "tags": ["definition", "interdependence", "coordination"],
      "embedding": [490, 260]
    },
    {
      "id": "survey-hat-lpm",
      "title": "A Survey on Human-AI Teaming with Large Pre-Trained Models",
      "authors": "Various",
      "year": 2024,
      "cluster": "teamwork",
      "summary": "Surveys how large language models are transforming human-AI teaming, from code generation to creative collaboration, identifying new patterns of human-AI task division.",
      "url": "",
      "source": "research",
      "designLevers": ["workflow", "capability_boundary"],
      "designerIntents": ["workflow_redesign", "tooling_selection"],
      "designQuestion": "How should task division patterns change now that LLMs can handle increasingly complex knowledge work?",
      "tags": ["LLMs", "survey", "task-division", "emerging"],
      "embedding": [535, 310]
    },
    {
      "id": "hat-empirical",
      "title": "Human-Autonomy Teaming: A Review and Analysis of the Empirical Literature",
      "authors": "O'Neill et al.",
      "year": 2020,
      "cluster": "teamwork",
      "summary": "Comprehensive meta-analysis of empirical studies on human-autonomy teaming, identifying key moderators of team effectiveness including task complexity and automation level.",
      "url": "",
      "source": "research",
      "designLevers": ["workflow", "capability_boundary"],
      "designerIntents": ["team_structure", "workflow_redesign"],
      "designQuestion": "At what level of task complexity does human-AI teaming outperform either humans or AI working alone?",
      "tags": ["meta-analysis", "empirical", "effectiveness"],
      "embedding": [475, 310]
    },
    {
      "id": "superteams",
      "title": "Artificial Intelligence Superteams & Augmentation Strategies",
      "authors": "Various",
      "year": 2024,
      "cluster": "teamwork",
      "summary": "Examines how organizations can build AI superteams through strategic augmentation, identifying patterns where AI amplifies human strengths rather than replacing human capabilities.",
      "url": "",
      "source": "industry",
      "designLevers": ["role", "workflow"],
      "designerIntents": ["team_structure", "workflow_redesign"],
      "designQuestion": "Which of your team's strengths could AI amplify, and which capabilities should remain exclusively human?",
      "tags": ["augmentation", "superteams", "strategy"],
      "embedding": [550, 270]
    },
    {
      "id": "team-challenges-ai",
      "title": "Team Challenges: Is Artificial Intelligence the Solution?",
      "authors": "Various",
      "year": 2024,
      "cluster": "teamwork",
      "summary": "Evaluates whether AI can address common team challenges including coordination failures, social loafing, and groupthink, finding mixed results depending on implementation.",
      "url": "",
      "source": "research",
      "designLevers": ["workflow", "governance"],
      "designerIntents": ["team_structure", "governance_policy"],
      "designQuestion": "Which of your team's recurring challenges could AI help solve, and which might it inadvertently worsen?",
      "tags": ["challenges", "coordination", "groupthink"],
      "embedding": [455, 355]
    },
    {
      "id": "hello-mate",
      "title": "Hello Mate! Insights from the Field on Leveraging Machine Teammates",
      "authors": "Various",
      "year": 2022,
      "cluster": "teamwork",
      "summary": "Field study of organizations using AI teammates, revealing practical insights about onboarding AI into existing teams, managing expectations, and sustaining engagement.",
      "url": "",
      "source": "research",
      "designLevers": ["ritual", "role"],
      "designerIntents": ["team_structure", "ritual_design"],
      "designQuestion": "What does a good 'first week' look like when onboarding an AI teammate into an established team?",
      "tags": ["field-study", "onboarding", "engagement"],
      "embedding": [525, 350]
    },
    {
      "id": "antecedents-hat",
      "title": "Examining the Antecedents of Human-AI Team Effectiveness",
      "authors": "Siemon et al.",
      "year": 2024,
      "cluster": "teamwork",
      "summary": "Identifies key antecedents of effective human-AI teaming including task design, team composition, communication protocols, and organizational support structures.",
      "url": "",
      "source": "research",
      "designLevers": ["workflow", "governance"],
      "designerIntents": ["team_structure", "governance_policy"],
      "designQuestion": "Which organizational support structures are prerequisites for effective human-AI teaming?",
      "tags": ["antecedents", "effectiveness", "organizational-support"],
      "embedding": [495, 370]
    },
    {
      "id": "genai-colleague",
      "title": "GenAI as a New Colleague",
      "authors": "Various",
      "year": 2024,
      "cluster": "delegation",
      "summary": "Examines how generative AI is being integrated as a virtual colleague in knowledge work, analyzing delegation patterns and the evolution of human-AI work distribution.",
      "url": "",
      "source": "industry",
      "designLevers": ["workflow", "role"],
      "designerIntents": ["workflow_redesign", "role_definition"],
      "designQuestion": "What tasks are your knowledge workers already informally delegating to GenAI, and should those delegation patterns be formalized?",
      "tags": ["genai", "delegation", "knowledge-work", "emerging"],
      "embedding": [790, 135]
    },
    {
      "id": "when-should-i-lead",
      "title": "When Should I Lead? Exploring Human-AI Leadership Dynamics",
      "authors": "Various",
      "year": 2024,
      "cluster": "delegation",
      "summary": "Investigates dynamic leadership allocation between humans and AI in team settings, finding that optimal performance requires flexible leadership transitions based on task context.",
      "url": "",
      "source": "research",
      "designLevers": ["role", "governance"],
      "designerIntents": ["role_definition", "governance_policy"],
      "designQuestion": "Under what conditions should AI take the lead in your team's workflow, and how do you signal those transitions?",
      "tags": ["leadership", "dynamics", "transitions"],
      "embedding": [815, 160]
    },
    {
      "id": "requirements-ai-teammates",
      "title": "Requirements for AI Teammates",
      "authors": "Various",
      "year": 2023,
      "cluster": "delegation",
      "summary": "Identifies core requirements for AI systems to function as effective teammates, including situational awareness, explainability, adaptability, and appropriate autonomy levels.",
      "url": "",
      "source": "research",
      "designLevers": ["capability_boundary", "interface"],
      "designerIntents": ["tooling_selection", "role_definition"],
      "designQuestion": "Which capability requirements should be non-negotiable before deploying an AI teammate in your context?",
      "tags": ["requirements", "autonomy", "capabilities"],
      "embedding": [835, 140]
    },
    {
      "id": "human-loop-orgs",
      "title": "Human-in-the-Loop in Organizations",
      "authors": "Various",
      "year": 2023,
      "cluster": "delegation",
      "summary": "Analyzes different models of human-in-the-loop AI deployment in organizations, from human oversight to human-AI co-decision making, with implications for accountability.",
      "url": "",
      "source": "research",
      "designLevers": ["governance", "workflow"],
      "designerIntents": ["governance_policy", "workflow_redesign"],
      "designQuestion": "Where should the human-in-the-loop boundary sit in your organization's AI deployment, and who decides when to move it?",
      "tags": ["HITL", "oversight", "accountability"],
      "embedding": [775, 175]
    },
    {
      "id": "algorithmic-management",
      "title": "Working With Machines: Algorithmic Management",
      "authors": "Various",
      "year": 2023,
      "cluster": "delegation",
      "summary": "Examines how algorithmic management reshapes workplace dynamics, exploring both efficiency gains and concerns about worker autonomy, surveillance, and dehumanization.",
      "url": "",
      "source": "research",
      "designLevers": ["governance", "workflow"],
      "designerIntents": ["governance_policy", "workflow_redesign"],
      "designQuestion": "How do you ensure algorithmic management amplifies worker agency rather than constraining it?",
      "tags": ["algorithmic-management", "autonomy", "surveillance"],
      "embedding": [820, 185]
    },
    {
      "id": "state-ai-work-anthropic",
      "title": "State of AI at Work",
      "authors": "Anthropic",
      "year": 2025,
      "cluster": "delegation",
      "summary": "Anthropic's industry report on current AI adoption patterns in workplaces, covering usage trends, productivity impacts, and emerging challenges in human-AI collaboration.",
      "url": "",
      "source": "industry",
      "designLevers": ["workflow", "capability_boundary"],
      "designerIntents": ["workflow_redesign", "tooling_selection"],
      "designQuestion": "How do your team's AI adoption patterns compare to industry benchmarks, and what gaps should you address first?",
      "tags": ["industry-report", "adoption", "productivity", "emerging"],
      "embedding": [760, 145]
    },
    {
      "id": "structuring-ai-comm",
      "title": "Structuring AI Teammate Communication: An Exploration of AI's Communication Strategies",
      "authors": "Various",
      "year": 2024,
      "cluster": "communication",
      "summary": "Explores how AI teammates should structure their communication, finding that proactive updates, explanation depth, and communication timing significantly affect team coordination.",
      "url": "",
      "source": "research",
      "designLevers": ["interface", "ritual"],
      "designerIntents": ["workflow_redesign", "ritual_design"],
      "designQuestion": "What communication cadence and format should your AI teammate use to keep the team informed without creating noise?",
      "tags": ["communication", "proactive-updates", "coordination"],
      "embedding": [190, 490]
    },
    {
      "id": "investigating-comm",
      "title": "Investigating Human-AI Team Communication Strategies",
      "authors": "Various",
      "year": 2024,
      "cluster": "communication",
      "summary": "Studies communication strategies in human-AI teams, revealing that effective AI teammates adapt communication style based on task urgency, team member expertise, and cognitive load.",
      "url": "",
      "source": "research",
      "designLevers": ["interface", "workflow"],
      "designerIntents": ["workflow_redesign", "tooling_selection"],
      "designQuestion": "How should your AI teammate adjust its communication style based on the urgency of the situation?",
      "tags": ["communication", "adaptive", "cognitive-load"],
      "embedding": [215, 520]
    },
    {
      "id": "purposeful-presentation",
      "title": "The Purposeful Presentation of AI Teammates Impacts Human Acceptance and Perception",
      "authors": "Various",
      "year": 2024,
      "cluster": "communication",
      "summary": "Demonstrates that how AI teammates are introduced and framed significantly influences human acceptance, with anthropomorphic presentations increasing trust but also raising expectations.",
      "url": "",
      "source": "research",
      "designLevers": ["interface", "role"],
      "designerIntents": ["role_definition", "team_structure"],
      "designQuestion": "How should you introduce and frame your AI teammate to set appropriate expectations from day one?",
      "tags": ["framing", "acceptance", "anthropomorphism"],
      "embedding": [175, 530]
    },
    {
      "id": "pursuit-happiness",
      "title": "The Pursuit of Happiness: The Power and Influence of AI Teammate Emotion in Human-AI Teamwork",
      "authors": "Various",
      "year": 2024,
      "cluster": "communication",
      "summary": "Investigates how emotional expressions by AI teammates influence team dynamics, finding that AI emotional displays can boost morale but may also feel manipulative if perceived as inauthentic.",
      "url": "",
      "source": "research",
      "designLevers": ["interface", "role"],
      "designerIntents": ["role_definition", "ritual_design"],
      "designQuestion": "Should your AI teammate express emotions, and how do you prevent emotional displays from feeling manipulative?",
      "tags": ["emotion", "authenticity", "morale", "emerging"],
      "embedding": [225, 475]
    },
    {
      "id": "politeness-llms",
      "title": "Politeness in Large Language Models",
      "authors": "Various",
      "year": 2024,
      "cluster": "communication",
      "summary": "Analyzes politeness norms in LLM interactions, finding that social conventions like politeness significantly influence AI output quality and user satisfaction in collaborative settings.",
      "url": "",
      "source": "research",
      "designLevers": ["interface", "ritual"],
      "designerIntents": ["ritual_design", "tooling_selection"],
      "designQuestion": "What social norms should govern how your team communicates with AI, and how does that shape AI behavior?",
      "tags": ["politeness", "social-norms", "LLMs"],
      "embedding": [165, 510]
    },
    {
      "id": "ai-explaining",
      "title": "AI Explaining Its Decisions",
      "authors": "Various",
      "year": 2023,
      "cluster": "communication",
      "summary": "Reviews approaches to AI explainability in team contexts, finding that explanation format, timing, and detail level must be calibrated to the user's expertise and decision criticality.",
      "url": "",
      "source": "research",
      "designLevers": ["interface", "capability_boundary"],
      "designerIntents": ["tooling_selection", "governance_policy"],
      "designQuestion": "What level of explanation does your team actually need from AI, and when does too much explanation become a burden?",
      "tags": ["explainability", "decision-making", "calibration"],
      "embedding": [235, 545]
    },
    {
      "id": "amershi-guidelines",
      "title": "Guidelines for Human-AI Interaction",
      "authors": "Amershi et al. (Microsoft)",
      "year": 2019,
      "cluster": "communication",
      "summary": "Foundational set of 18 design guidelines for human-AI interaction, covering initial interaction, during interaction, when wrong, and over time, widely adopted across the industry.",
      "url": "",
      "source": "industry",
      "designLevers": ["interface", "workflow"],
      "designerIntents": ["tooling_selection", "workflow_redesign"],
      "designQuestion": "Which of the 18 guidelines does your AI product violate, and what would it take to bring it into alignment?",
      "tags": ["guidelines", "design-patterns", "foundational"],
      "embedding": [205, 555]
    },
    {
      "id": "how-make-agents",
      "title": "How to Make Agents and Influence Teammates: Understanding the Social Dynamics",
      "authors": "Various",
      "year": 2024,
      "cluster": "communication",
      "summary": "Studies social influence dynamics in human-AI teams, finding that AI agents can shape team behavior through suggestion framing, timing, and social proof mechanisms.",
      "url": "",
      "source": "research",
      "designLevers": ["interface", "governance"],
      "designerIntents": ["governance_policy", "role_definition"],
      "designQuestion": "How do you prevent AI social influence from undermining human autonomy in team decision-making?",
      "tags": ["social-influence", "agents", "decision-making", "emerging"],
      "embedding": [245, 490]
    },
    {
      "id": "mutual-tom",
      "title": "Mutual Theory of Mind in AI",
      "authors": "Various",
      "year": 2024,
      "cluster": "learning",
      "summary": "Proposes that effective human-AI teaming requires mutual theory of mind where both humans and AI maintain models of each other's knowledge, intentions, and capabilities.",
      "url": "",
      "source": "research",
      "designLevers": ["interface", "capability_boundary"],
      "designerIntents": ["tooling_selection", "learning_upskilling"],
      "designQuestion": "How well does your AI understand what you know and don't know, and how well do you understand what your AI can and can't do?",
      "tags": ["theory-of-mind", "mutual-modeling", "emerging"],
      "embedding": [490, 540]
    },
    {
      "id": "shared-mental-models",
      "title": "Let's Think Together: Shared Mental Models in Human-AI Teams",
      "authors": "Various",
      "year": 2024,
      "cluster": "learning",
      "summary": "Examines how shared mental models develop between humans and AI, finding that explicit model sharing and calibration exercises improve team decision-making accuracy.",
      "url": "",
      "source": "research",
      "designLevers": ["ritual", "interface"],
      "designerIntents": ["learning_upskilling", "ritual_design"],
      "designQuestion": "What exercises or rituals could help your team build shared mental models with AI?",
      "tags": ["shared-mental-models", "calibration", "decision-making"],
      "embedding": [520, 560]
    },
    {
      "id": "collective-attention",
      "title": "Collective Attention in Human-AI Teams",
      "authors": "Various",
      "year": 2024,
      "cluster": "learning",
      "summary": "Studies how attention is distributed across human-AI teams, revealing patterns of collective attention allocation that predict team performance and error rates.",
      "url": "",
      "source": "research",
      "designLevers": ["workflow", "interface"],
      "designerIntents": ["workflow_redesign", "team_structure"],
      "designQuestion": "How do you ensure critical information gets the right attention when it's distributed across human and AI team members?",
      "tags": ["attention", "performance", "error-rates"],
      "embedding": [475, 575]
    },
    {
      "id": "collective-intelligence",
      "title": "Human-AI Collective Intelligence",
      "authors": "Various",
      "year": 2024,
      "cluster": "learning",
      "summary": "Explores how human-AI teams can achieve collective intelligence that exceeds either human or AI capabilities alone through complementary expertise and adaptive coordination.",
      "url": "",
      "source": "research",
      "designLevers": ["workflow", "role"],
      "designerIntents": ["team_structure", "workflow_redesign"],
      "designQuestion": "What unique forms of collective intelligence emerge when humans and AI combine their complementary strengths?",
      "tags": ["collective-intelligence", "complementarity", "synergy", "emerging"],
      "embedding": [540, 545]
    },
    {
      "id": "leveraging-team-cognition",
      "title": "Leveraging AI for Team Cognition in Human-AI Teams",
      "authors": "Various",
      "year": 2024,
      "cluster": "learning",
      "summary": "Investigates how AI can support team cognitive processes including shared situational awareness, transactive memory, and collective sensemaking in complex environments.",
      "url": "",
      "source": "research",
      "designLevers": ["workflow", "interface"],
      "designerIntents": ["learning_upskilling", "workflow_redesign"],
      "designQuestion": "How could AI serve as a team's cognitive amplifier rather than a cognitive crutch?",
      "tags": ["team-cognition", "situational-awareness", "sensemaking"],
      "embedding": [505, 585]
    },
    {
      "id": "we-train-ai",
      "title": "We Train AI, Why Not Humans Too? Exploring Human-AI Team Training",
      "authors": "Various",
      "year": 2024,
      "cluster": "learning",
      "summary": "Argues for bidirectional training in human-AI teams where humans learn to work effectively with AI while AI systems are calibrated to team-specific interaction patterns.",
      "url": "",
      "source": "research",
      "designLevers": ["ritual", "capability_boundary"],
      "designerIntents": ["learning_upskilling", "ritual_design"],
      "designQuestion": "What does a training program for human-AI teaming look like, and who designs the curriculum?",
      "tags": ["training", "bidirectional", "upskilling"],
      "embedding": [460, 555]
    },
    {
      "id": "improving-collab",
      "title": "Improving Human-AI Collaboration with AI Behaviors",
      "authors": "Various",
      "year": 2024,
      "cluster": "learning",
      "summary": "Demonstrates that specific AI behavioral patterns including proactive information sharing, uncertainty communication, and adaptive pacing significantly improve collaboration outcomes.",
      "url": "",
      "source": "research",
      "designLevers": ["interface", "workflow"],
      "designerIntents": ["tooling_selection", "workflow_redesign"],
      "designQuestion": "Which AI behavioral patterns most improve collaboration in your specific work context?",
      "tags": ["AI-behaviors", "collaboration", "uncertainty"],
      "embedding": [530, 525]
    },
    {
      "id": "skills-humans-need",
      "title": "Human-Machine Teams: What Skills Do the Humans Need?",
      "authors": "Dubrow & Orvis",
      "year": 2020,
      "cluster": "learning",
      "summary": "Identifies essential human skills for effective human-machine teaming including AI literacy, adaptive coordination, calibrated trust, and collaborative problem-solving.",
      "url": "",
      "source": "research",
      "designLevers": ["capability_boundary", "ritual"],
      "designerIntents": ["learning_upskilling", "team_structure"],
      "designQuestion": "Which human skills does your team need to develop to work effectively alongside AI?",
      "tags": ["skills", "AI-literacy", "human-development"],
      "embedding": [485, 595]
    },
    {
      "id": "hcai-hat",
      "title": "Applying Human-Centered AI in Developing Effective Human-AI Teaming",
      "authors": "Various",
      "year": 2023,
      "cluster": "ethics",
      "summary": "Demonstrates how human-centered AI principles can guide the development of effective human-AI teams, balancing automation benefits with human agency and oversight.",
      "url": "",
      "source": "research",
      "designLevers": ["governance", "interface"],
      "designerIntents": ["governance_policy", "tooling_selection"],
      "designQuestion": "How do you ensure your AI teammate's design keeps humans centered rather than sidelined?",
      "tags": ["human-centered-AI", "agency", "oversight"],
      "embedding": [790, 485]
    },
    {
      "id": "ethics-hat",
      "title": "Ethics in Human-AI Teaming",
      "authors": "Various",
      "year": 2024,
      "cluster": "ethics",
      "summary": "Maps the ethical landscape of human-AI teaming including questions of accountability, bias amplification, power dynamics, and the moral status of AI teammates.",
      "url": "",
      "source": "research",
      "designLevers": ["governance", "role"],
      "designerIntents": ["governance_policy", "role_definition"],
      "designQuestion": "Who is accountable when an AI teammate's action causes harm, and how do you establish that chain of responsibility?",
      "tags": ["ethics", "accountability", "bias", "power-dynamics"],
      "embedding": [815, 510]
    },
    {
      "id": "towards-ethical-ai",
      "title": "Towards Ethical AI in Teams",
      "authors": "Various",
      "year": 2024,
      "cluster": "ethics",
      "summary": "Proposes an ethical framework for AI integration in teams that addresses fairness in task allocation, transparency in AI reasoning, and preservation of human dignity.",
      "url": "",
      "source": "research",
      "designLevers": ["governance", "workflow"],
      "designerIntents": ["governance_policy", "workflow_redesign"],
      "designQuestion": "How do you ensure AI task allocation is fair and doesn't systematically disadvantage certain team members?",
      "tags": ["ethics", "fairness", "dignity", "framework"],
      "embedding": [835, 490]
    },
    {
      "id": "synthetic-authority",
      "title": "Synthetic Authority: The Impact of AI on Organizational Power Dynamics",
      "authors": "Various",
      "year": 2024,
      "cluster": "ethics",
      "summary": "Examines how AI introduces new forms of authority in organizations, potentially disrupting traditional power structures and creating novel accountability challenges.",
      "url": "",
      "source": "research",
      "designLevers": ["governance", "role"],
      "designerIntents": ["governance_policy", "team_structure"],
      "designQuestion": "How does AI redistribute power in your organization, and who gains or loses authority?",
      "tags": ["authority", "power-dynamics", "organizational-change", "emerging"],
      "embedding": [775, 520]
    },
    {
      "id": "ai-culture",
      "title": "AI and Culture",
      "authors": "Goldberg & Srivastava",
      "year": 2024,
      "cluster": "ethics",
      "summary": "Explores the bidirectional relationship between AI and organizational culture, examining how cultural values shape AI adoption and how AI in turn transforms workplace culture.",
      "url": "",
      "source": "research",
      "designLevers": ["ritual", "governance"],
      "designerIntents": ["ritual_design", "governance_policy"],
      "designQuestion": "How is AI reshaping your team's culture, and are those cultural shifts intentional or accidental?",
      "tags": ["culture", "values", "organizational-change"],
      "embedding": [825, 540]
    },
    {
      "id": "soul-of-work",
      "title": "The Soul of Work in the Age of AI",
      "authors": "Various",
      "year": 2024,
      "cluster": "ethics",
      "summary": "Philosophical exploration of how AI integration challenges fundamental concepts of meaningful work, professional identity, and human purpose in the workplace.",
      "url": "",
      "source": "research",
      "designLevers": ["role", "governance"],
      "designerIntents": ["role_definition", "governance_policy"],
      "designQuestion": "What makes work meaningful when AI can do many of the tasks that once defined your professional identity?",
      "tags": ["meaning", "identity", "philosophy", "emerging"],
      "embedding": [805, 555]
    },
    {
      "id": "human-ai-cocreation",
      "title": "Human-AI Co-Creation",
      "authors": "Various",
      "year": 2024,
      "cluster": "creativity",
      "summary": "Studies co-creative processes between humans and AI, identifying patterns where human creativity and AI capabilities combine to produce outcomes neither could achieve alone.",
      "url": "",
      "source": "research",
      "designLevers": ["workflow", "interface"],
      "designerIntents": ["workflow_redesign", "tooling_selection"],
      "designQuestion": "What does a truly co-creative workflow between humans and AI look like, beyond just 'human prompts, AI generates'?",
      "tags": ["co-creation", "creative-process", "synergy"],
      "embedding": [340, 110]
    },
    {
      "id": "human-ai-cocreativity",
      "title": "Human-AI Co-Creativity: Exploring Shared Creative Processes",
      "authors": "Various",
      "year": 2024,
      "cluster": "creativity",
      "summary": "Examines shared creative processes in human-AI teams, finding that iterative cycles of human ideation and AI elaboration produce the most novel creative outcomes.",
      "url": "",
      "source": "research",
      "designLevers": ["workflow", "ritual"],
      "designerIntents": ["workflow_redesign", "ritual_design"],
      "designQuestion": "How many iteration cycles between human ideation and AI elaboration produce the best creative results for your team?",
      "tags": ["co-creativity", "iteration", "ideation"],
      "embedding": [365, 135]
    },
    {
      "id": "focus-modality-design",
      "title": "Focus and Modality: Defining a Roadmap to Future AI-Human Teaming in Design",
      "authors": "Various",
      "year": 2024,
      "cluster": "creativity",
      "summary": "Maps out how AI-human teaming will evolve in design practice across different modalities, from visual to conversational to spatial, with implications for design education.",
      "url": "",
      "source": "research",
      "designLevers": ["interface", "capability_boundary"],
      "designerIntents": ["tooling_selection", "learning_upskilling"],
      "designQuestion": "Which design modality (visual, conversational, spatial) is most ripe for AI-human teaming in your practice?",
      "tags": ["design", "modality", "education", "roadmap"],
      "embedding": [320, 140]
    },
    {
      "id": "genai-task-performance",
      "title": "Human-GenAI Collaboration to Enhance Task Performance",
      "authors": "Various",
      "year": 2024,
      "cluster": "creativity",
      "summary": "Empirical study showing that human-GenAI collaboration enhances task performance in knowledge work, with the largest gains in tasks requiring both analytical and creative thinking.",
      "url": "",
      "source": "research",
      "designLevers": ["workflow", "capability_boundary"],
      "designerIntents": ["workflow_redesign", "tooling_selection"],
      "designQuestion": "Which of your team's tasks sit at the intersection of analytical and creative thinking where GenAI collaboration adds the most value?",
      "tags": ["task-performance", "knowledge-work", "empirical"],
      "embedding": [375, 105]
    }
  ],
  "links": [
    { "source": "shaping-trust", "target": "trust-digital-teams" },
    { "source": "impacts-trust-model", "target": "shaping-trust" },
    { "source": "trust-ai-team-member", "target": "shaping-trust" },
    { "source": "trust-ai-team-member", "target": "impacts-trust-model" },
    { "source": "tools-to-teammates", "target": "beyond-tool-teammate" },
    { "source": "ideal-human", "target": "tools-to-teammates" },
    { "source": "who-what-teammate", "target": "defining-hat" },
    { "source": "when-ai-joins", "target": "who-what-teammate" },
    { "source": "survey-hat-lpm", "target": "hat-empirical" },
    { "source": "superteams", "target": "tools-to-teammates" },
    { "source": "team-challenges-ai", "target": "when-ai-joins" },
    { "source": "hello-mate", "target": "ideal-human" },
    { "source": "antecedents-hat", "target": "hat-empirical" },
    { "source": "genai-colleague", "target": "when-should-i-lead" },
    { "source": "requirements-ai-teammates", "target": "human-loop-orgs" },
    { "source": "algorithmic-management", "target": "human-loop-orgs" },
    { "source": "state-ai-work-anthropic", "target": "genai-colleague" },
    { "source": "structuring-ai-comm", "target": "investigating-comm" },
    { "source": "purposeful-presentation", "target": "structuring-ai-comm" },
    { "source": "pursuit-happiness", "target": "purposeful-presentation" },
    { "source": "politeness-llms", "target": "structuring-ai-comm" },
    { "source": "ai-explaining", "target": "amershi-guidelines" },
    { "source": "how-make-agents", "target": "structuring-ai-comm" },
    { "source": "mutual-tom", "target": "shared-mental-models" },
    { "source": "collective-attention", "target": "collective-intelligence" },
    { "source": "leveraging-team-cognition", "target": "shared-mental-models" },
    { "source": "we-train-ai", "target": "skills-humans-need" },
    { "source": "improving-collab", "target": "mutual-tom" },
    { "source": "hcai-hat", "target": "ethics-hat" },
    { "source": "towards-ethical-ai", "target": "ethics-hat" },
    { "source": "synthetic-authority", "target": "algorithmic-management" },
    { "source": "ai-culture", "target": "soul-of-work" },
    { "source": "human-ai-cocreation", "target": "human-ai-cocreativity" },
    { "source": "focus-modality-design", "target": "human-ai-cocreation" },
    { "source": "genai-task-performance", "target": "human-ai-cocreativity" },
    { "source": "trust-digital-teams", "target": "defining-hat" },
    { "source": "shared-mental-models", "target": "collective-intelligence" },
    { "source": "amershi-guidelines", "target": "hcai-hat" },
    { "source": "beyond-tool-teammate", "target": "defining-hat" },
    { "source": "when-should-i-lead", "target": "requirements-ai-teammates" },
    { "source": "investigating-comm", "target": "amershi-guidelines" }
  ]
}
